{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch EO Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch EO core design revolves around `Tasks`. Examples of tasks are: image classification, object detection, image segmentation, etc.\n",
    "\n",
    "A task is defined by:\n",
    "1. `model`: a neural network that will be trained to perform the task\n",
    "2. `hparams`: hyperparameters used to train the model (optimizer, scheduler and additional information)\n",
    "3. `loss function`: criterion used during the optimization process\n",
    "4. `metrics`: evaluation of the model in the task\n",
    "5. `inputs` and `outputs`: lists with the names of the inputs-outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models are neural networks that take inputs and produce outputs. You can build your own or use third party models. By default we use `torchvision`, so you can use any model from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1000])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from pytorch_eo.tasks.BaseTask import BaseTask\n",
    "\n",
    "task = BaseTask('resnet18')\n",
    "\n",
    "output = task(torch.randn(32,3,224,224))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you use models from torchvision, you can pass any parameter in the `hparams` object as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = {\n",
    "    'model': {\n",
    "        'pretrained': True\n",
    "    }\n",
    "}\n",
    "\n",
    "task = BaseTask('resnet18', hparams)\n",
    "\n",
    "output = task(torch.randn(32,3,224,224))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always make your own models, for example modifying an existing model from torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, 10)\n",
    "\n",
    "task = BaseTask(model)\n",
    "\n",
    "output = task(torch.randn(32,3,224,224))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or building your own model from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, pretrained, num_classes):\n",
    "        super().__init__()\n",
    "        resnet = torchvision.models.resnet18(pretrained=pretrained)\n",
    "        self.backbone = torch.nn.Sequential(*list(resnet.children())[:-2])\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        f = self.backbone(x)\n",
    "        return self.fc(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel(pretrained=True, num_classes=10)\n",
    "\n",
    "task = BaseTask(model)\n",
    "\n",
    "output = task(torch.randn(32, 3, 224,224))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you would probably want to use third party implementations with extra functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 112, 112])\n",
      "torch.Size([32, 64, 56, 56])\n",
      "torch.Size([32, 128, 28, 28])\n",
      "torch.Size([32, 256, 14, 14])\n",
      "torch.Size([32, 512, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "import timm \n",
    "\n",
    "model = timm.create_model(\n",
    "    'resnet18',\n",
    "    pretrained='imagenet',\n",
    "    in_chans=3,\n",
    "    num_classes=10,\n",
    "    features_only=True\n",
    ")\n",
    "\n",
    "task = BaseTask(model)\n",
    "\n",
    "output = task(torch.randn(32,3,224,224))\n",
    "for o in output:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 224, 224])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name='resnet18',\n",
    "    encoder_weights='imagenet',\n",
    "    in_channels=3,\n",
    "    classes=2,\n",
    ")\n",
    "\n",
    "task = BaseTask(model)\n",
    "\n",
    "output = task(torch.randn(32,3,224,224))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hparams\n",
    "\n",
    "This is a `dict` holding the hyperparameters used for training. Pytorch lightning will save the object in the model's checkpoint (that can be used to resume training, for example) so make sure to add any additional information that you want to save. In some cases, default parameters will be used if hparams are not provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    # hparams used for training\n",
    "    'model': { # only if you use default torchvision models\n",
    "        'pretrained': True\n",
    "    },\n",
    "    'loss': 'CrossEntropyLoss', # choose one from pytorch docs\n",
    "    'loss_params': {}, \n",
    "    'optimizer': 'Adam', # choose one from pytorch docs\n",
    "    'optim_params': {\n",
    "        'lr': 1e-4\n",
    "    },\n",
    "    'scheduler': 'CosineAnnealingLR', # choose one from pytorch docs\n",
    "    'scheduler_params': {\n",
    "        'T_max': 10,\n",
    "        'verbose': True\n",
    "    }\n",
    "    # extra\n",
    "    # epochs, batch size, model, transforms, ...\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify the loss function to use during training as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import torch\n",
    "import timm \n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.resnet18(pretrained=True)\n",
    "        self.model.fc = torch.nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = rearrange(x, 'b h w c -> b c h w')\n",
    "        x = (x / 255).float()\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | Model            | 11.2 M\n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "22.363    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9da74e8da94bdfba19860946332826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/juan/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65eebb87e9147efa4c0cddbdfb5f322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb264bed602c49eab6cb96e6dd1f9c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372e4498a0b64b08954523a64f9d5db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43f5b74ba984151b82faaad8b1be06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "from pytorch_eo.datasets import EuroSATRGB\n",
    "from pytorch_eo.tasks import ImageClassification\n",
    "from pytorch_eo.metrics.classification import accuracy\n",
    "\n",
    "ds = EuroSATRGB(batch_size=32)\n",
    "model =  Model(ds.num_classes)\n",
    "\n",
    "task = ImageClassification(model, loss_fn=torch.nn.CrossEntropyLoss())\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    precision=16,\n",
    "    max_epochs=3,\n",
    "    limit_train_batches=10\n",
    ")\n",
    "\n",
    "trainer.fit(task, ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last piece to train a model is the metrics. You can train without metrics, use our simple convenient implementations, or use your own implementations. In most tasks we will use at least one metric even if they are not provided (they are that important !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import torch\n",
    "import timm \n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.resnet18(pretrained=True)\n",
    "        self.model.fc = torch.nn.Linear(512, ds.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = rearrange(x, 'b h w c -> b c h w')\n",
    "        x = (x / 255).float()\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "from pytorch_eo.datasets import EuroSATRGB\n",
    "from pytorch_eo.tasks import ImageClassification\n",
    "from pytorch_eo.metrics.classification import accuracy\n",
    "\n",
    "ds = EuroSATRGB(batch_size=32)\n",
    "model =  Model(ds.num_classes)\n",
    "\n",
    "metrics = {'acc': accuracy}\n",
    "\n",
    "task = ImageClassification(model, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | Model            | 11.2 M\n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "22.363    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375e59f2fdce4a8a9cfeec75faa95637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/juan/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/juan/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37b3d81057e4bc38e13e009b74a8e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b586269454f456f9c3f0d296f7d04aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf00c7fd84c842dabc3c4089ab2486cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0964b64c5a744a6bd93b774b020fc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    precision=16,\n",
    "    max_epochs=3,\n",
    "    limit_train_batches=10\n",
    ")\n",
    "\n",
    "trainer.fit(task, ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use as many metrics as you want (all will be logged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_accuracy(y_hat, y):\n",
    "    return (torch.argmax(y_hat, axis=1) == y).sum() / y.shape[0]\n",
    "\n",
    "metrics = {'acc': accuracy, 'my_acc': my_accuracy}\n",
    "\n",
    "task = ImageClassification(model, hparams, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | Model            | 11.2 M\n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "22.363    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b3e01a633e405e9097ca57ef08a892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89ad71480354a08aaff99c2dfe18df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.7553e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df4c0b2915d499eb6d051f80b2b013f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.0451e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7322b7e382274cd187a1b838c542271e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.9389e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251ecc15bd0f4606ac1ce8d22dac25d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    precision=16,\n",
    "    max_epochs=3,\n",
    "    limit_train_batches=10\n",
    ")\n",
    "\n",
    "trainer.fit(task, ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you would probably want to use a third party library like `torchmetrics` with a lot of tested implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import accuracy as tm_accuracy\n",
    "\n",
    "# torchmetrics wants probas\n",
    "def my_tm_accuracy(y_pred, y):\n",
    "    y_pred = torch.softmax(y_pred, 1)\n",
    "    return tm_accuracy(y_pred, y)\n",
    "\n",
    "metrics = {'acc': accuracy, 'my_acc': my_accuracy, 'tm_acc': my_tm_accuracy}\n",
    "\n",
    "task = ImageClassification(model, hparams, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | Model            | 11.2 M\n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "22.363    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bf4f69aaa0438bb67970801350fe43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e2a41fdb1947c8b5e34a0175894604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.7553e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab92a46d2c3d40a5951a92a38118bbb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.0451e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abee1d7974b4d8d82c939cb05bb8b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.9389e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98f74f818044553b6803cb9923316aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    precision=16,\n",
    "    max_epochs=3,\n",
    "    limit_train_batches=10\n",
    ")\n",
    "\n",
    "trainer.fit(task, ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs and Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PytorchEO datasets are designed to be flexible in the number and modality of inputs and outputs in order to allow for advanced applications such as data fusion, unsupervised learning or multi-task learning. For this reason, you must tell the task which fields in your datasets have to be used for inputs and outputs, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pytorch_eo.utils import download_url, unzip_file\n",
    "from pathlib import Path\n",
    "from pytorch_eo.datasets import RGBImageDataset\n",
    "from pytorch_eo.datasets import ConcatDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def prepare_data(path):\n",
    "\tos.makedirs(path, exist_ok=True)\n",
    "\turl = \"http://madm.dfki.de/files/sentinel/EuroSAT.zip\"\n",
    "\tcompressed_data_filename = 'EuroSAT.zip'\n",
    "\tdata_folder = '2750'\n",
    "\tcompressed_data_path = path / compressed_data_filename\n",
    "\tdownload_url(url, compressed_data_path)\n",
    "\tunzip_file(compressed_data_path, path, msg=\"extracting data ...\")\n",
    "\tuncompressed_data_path = path / data_folder\n",
    "\tclasses = sorted(os.listdir(uncompressed_data_path))\n",
    "\timages, labels = [], []\n",
    "\tfor ix, label in enumerate(classes):\n",
    "\t\t_images = os.listdir(uncompressed_data_path / label)\n",
    "\t\timages += [str(uncompressed_data_path /\n",
    "\t\t\t\t\tlabel / img) for img in _images]\n",
    "\t\tlabels += [ix]*len(_images)\n",
    "\treturn images, labels\n",
    "\n",
    "class EuroSATDataset(pl.LightningDataModule):\n",
    "\tdef __init__(self, path='data'):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.path = Path(path)\n",
    "\n",
    "\tdef setup(self, stage=None):\n",
    "\t\timages, labels = prepare_data(self.path)\n",
    "\t\timages_ds = RGBImageDataset(images) \n",
    "\t\t# Custom keys in the dataset !\n",
    "\t\tself.ds = ConcatDataset({'abc': images_ds, 'def': labels})\n",
    "\n",
    "\tdef train_dataloader(self):\n",
    "\t\treturn DataLoader(self.ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/juan/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "extracting data ...: 100%|██████████| 27011/27011 [00:02<00:00, 9903.89it/s] \n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | Model            | 11.2 M\n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "22.363    Total estimated model params size (MB)\n",
      "/home/juan/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/juan/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfac049e6cd341efb3ede4b15f2015e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = EuroSATDataset()\n",
    "model =  Model(10)\n",
    "\n",
    "task = ImageClassification(model, inputs=['abc'], outputs=['def'])\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    precision=16,\n",
    "    max_epochs=3,\n",
    "    limit_train_batches=10\n",
    ")\n",
    "\n",
    "trainer.fit(task, ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks are `LightningModule`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, note that `Tasks` are built on top of `Pytorch Lightning`'s `LightningModule`, so you can build your own tasks easily and use any of our `Datasets` (which are in turn `LightningDataModule`s)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74dbfc52f168b3071122cf9c0781887d6121c12f9c1b29bca56ce221bccb2a07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
