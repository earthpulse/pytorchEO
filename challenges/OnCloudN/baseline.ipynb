{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will learn how to get started with PytorchEO training a baseline model for the [On Cloud N](https://www.drivendata.org/competitions/83/cloud-cover/): Cloud Cover Detection Challenge, following the baseline published by the authors [here](https://www.drivendata.co/blog/cloud-cover-benchmark/).\n",
    "\n",
    "> ðŸš§ PytorchEO is in early stages of development, documentation is lacking and API may change in the future. Please let us know if you find it useful to push forward its development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PytorchEO is built around `Datasets` and `Tasks`. In this challenge we are asked to solve an image segmentation task with a dataset composed of Sentinel 2 images with corresponding cloud masks. \n",
    "\n",
    "> Before continuing, please join the challenge and download the [data](https://www.drivendata.org/competitions/83/cloud-cover/data/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Pytorch EO imports\n",
    "from pytorch_eo.datasets.BaseDataset import BaseDataset\n",
    "from pytorch_eo.utils.datasets.ConcatDataset import ConcatDataset\n",
    "from pytorch_eo.utils.datasets.SingleBandImageDataset import SingleBandImageDataset\n",
    "from pytorch_eo.utils.datasets.RGBImageDataset import RGBImageDataset\n",
    "from pytorch_eo.utils.sensors import Sensors\n",
    "\n",
    "# The BaseDataset will handle data splitting and loading with pytorch dataloaders\n",
    "# https://github.com/earthpulse/pytorch_eo/blob/main/pytorch_eo/datasets/BaseDataset.py\n",
    "\n",
    "class OnCloudNDataset(BaseDataset): \n",
    "\n",
    "    def __init__(self,\n",
    "                 batch_size=32,\n",
    "                 path='data', \n",
    "                 data_folder='train_features', \n",
    "                 labels_folder='train_labels',\n",
    "                 metadata_path='train_metadata.csv',\n",
    "                 test_size=0.2,\n",
    "                 val_size=0.2,\n",
    "                 train_trans=None,\n",
    "                 val_trans=None,\n",
    "                 test_trans=None,\n",
    "                 num_workers=0,\n",
    "                 pin_memory=False,\n",
    "                 seed=42,\n",
    "                 verbose=False,\n",
    "                 bands=None,\n",
    "                 ):\n",
    "        super().__init__(batch_size, test_size, val_size,\n",
    "                         verbose, num_workers, pin_memory, seed)\n",
    "        self.path = Path(path)\n",
    "        self.metadata_path = metadata_path\n",
    "        self.data_folder = data_folder\n",
    "        self.labels_folder = labels_folder\n",
    "        self.train_trans = train_trans\n",
    "        self.val_trans = val_trans\n",
    "        self.test_trans = test_trans\n",
    "        self.bands = bands\n",
    "        self.num_classes = 2\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # read csv with metadata\n",
    "        train_metadata = pd.read_csv(self.path / self.metadata_path)\n",
    "\n",
    "        # generate paths to images and masks\n",
    "        images = train_metadata.chip_id.apply(\n",
    "            lambda cid: f'{self.path}/{self.data_folder}/{cid}')\n",
    "        masks = train_metadata.chip_id.apply(\n",
    "            lambda cid: f'{self.path}/{self.labels_folder}/{cid}.tif')\n",
    "\n",
    "        # build dataframe and splits\n",
    "        self.df = pd.DataFrame({'image': images, 'mask': masks})\n",
    "        self.make_splits()\n",
    "\n",
    "        # generate datasets\n",
    "        self.build_datasets()\n",
    "\n",
    "    def build_dataset(self, df, trans):\n",
    "        return ConcatDataset({\n",
    "            'image': SingleBandImageDataset(df.image.values, Sensors.S2, self.bands),\n",
    "            'mask': RGBImageDataset(df['mask'].values, dtype=np.float32)\n",
    "        }, trans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use any model that you want with PytorchEO. In this example we use the [Pytorch Segmentation Models](https://github.com/qubvel/segmentation_models.pytorch) library to build a simple UNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "from einops import rearrange\n",
    "import torch\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "\tdef __init__(self, in_chans=3, backbone='resnet34', num_classes=1, max_value=4000, pretrained=None):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.model = smp.Unet(\n",
    "\t\t\tencoder_name=backbone,\n",
    "\t\t\tencoder_weights=pretrained, # imagenet\n",
    "\t\t\tin_channels=in_chans,\n",
    "\t\t\tclasses=num_classes,\n",
    "\t\t)\n",
    "\t\tself.max_value = max_value\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = rearrange(x, 'b h w c -> b c h w')\n",
    "\t\tx = x / self.max_value\n",
    "\t\tx = x.clip(0., 1.)\n",
    "\t\ty = self.model(x).squeeze(1) # remove channels dim\n",
    "\t\treturn y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PytorchEO comes with several tasks built in, and more to come. In this case, we use the `ImageSegmentationTask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_eo.tasks.segmentation import ImageSegmentation\n",
    "\n",
    "model = Model()\n",
    "\n",
    "task = ImageSegmentation(model)\n",
    "\n",
    "out = task(torch.randn(32, 512, 512, 3))\n",
    "\n",
    "out.shape, out.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [PytorchLighning](https://pytorch-lightning.readthedocs.io/) for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl \n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_eo.utils.sensors import S2\n",
    "\n",
    "bands = [S2.blue, S2.green, S2.red, S2.nir1]\n",
    "\n",
    "ds = OnCloudNDataset(\n",
    "    batch_size=10, \n",
    "    bands=bands,\n",
    ")\n",
    "\n",
    "model = Model(in_chans=len(bands))\n",
    "\n",
    "task = ImageSegmentation(model)\n",
    "\n",
    "# overfit batches to check if model is working\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "\tmax_epochs=30,\n",
    "\toverfit_batches=1,\n",
    "    checkpoint_callback=False,\n",
    "\tlogger=None,\n",
    "\tgpus=1,\n",
    "\tprecision=16,\n",
    ")\n",
    "\n",
    "trainer.fit(task, ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to add your favourite callbacks, accelerators, data augmentation... The following is a more complete example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A \n",
    "\n",
    "pl.seed_everything(42, workers=True) # make results reproducible\n",
    "\n",
    "trans = A.Compose([ # some data augmentation (we use albumentations)\n",
    "\tA.RandomRotate90(),\n",
    "\tA.HorizontalFlip(),\n",
    "\tA.VerticalFlip(),\n",
    "])\n",
    "\n",
    "bands = [S2.blue, S2.green, S2.red, S2.nir1] # choose any bands combination\n",
    "\n",
    "ds = OnCloudNDataset(\n",
    "    batch_size=64, # increase the batch size to fully use your GPU\n",
    "    bands=bands,\n",
    "    num_workers=20, # faster data loading (put here your CPU core count)\n",
    "    pin_memory=True, # faster data loading\n",
    "    train_trans=trans,\n",
    ")\n",
    "\n",
    "model = Model(in_chans=len(bands))\n",
    "\n",
    "hparams = { # customize optimizer\n",
    "    'optimizer': 'Adam',\n",
    "    'optim_params': {\n",
    "        'lr': 1e-3\n",
    "    },\n",
    "\t'scheduler': 'MultiStepLR',\n",
    "\t'scheduler_params': {\n",
    "\t\t'milestones': [3, 6],\n",
    "\t\t'verbose': True\n",
    "\t} # add anything you want to save as hparams with your model\n",
    "}\n",
    "\n",
    "# customize your metrics (use as many as you want)\n",
    "\n",
    "def iou(pr, gt, th=0.5, eps=1e-7):\n",
    "        mask = gt.ne(255) # ignore value 255 in mask\n",
    "        gt = gt.masked_select(mask)\n",
    "        pr = pr.masked_select(mask)\n",
    "        pr = torch.sigmoid(pr) > th\n",
    "        gt = gt > th \n",
    "        intersection = torch.sum(gt & pr)\n",
    "        union = torch.sum(gt | pr)\n",
    "        return intersection / (union + eps)\n",
    "\n",
    "metrics = {'iou': iou} \n",
    "\n",
    "# customize your loss function\n",
    "\n",
    "loss_fn = smp.losses.SoftBCEWithLogitsLoss(ignore_index=255) # ignore value 255 in mask\n",
    "\n",
    "# train the model\n",
    "\n",
    "task = ImageSegmentation(model, hparams=hparams, metrics=metrics, loss_fn=loss_fn)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    gpus=1,\n",
    "    precision=16,\n",
    "    callbacks=[ # save best model during training\n",
    "\t\tModelCheckpoint(\n",
    "\t\t\tdirpath='./',\n",
    "\t\t\tfilename=f\"unet-baseline-{{val_iou:.4f}}\",\n",
    "\t\t\tsave_top_k=1,\n",
    "\t\t\tmonitor='val_iou',\n",
    "\t\t\tmode='max'\n",
    "\t\t)\n",
    "\t],\n",
    "\tdeterministic=True, # make results reproducible\n",
    ")\n",
    "\n",
    "trainer.fit(task, ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a code submission challenge, you can find an example on how to submit [here](https://www.drivendata.co/blog/cloud-cover-benchmark/). First, we have to export our model, in this case using `torchscript`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally, load from checkpoint\n",
    "cpu_model = model.cpu()\n",
    "sample_input_cpu = torch.randn(32, 512, 512, len(bands))\n",
    "traced_cpu = torch.jit.trace(cpu_model, sample_input_cpu)\n",
    "torch.jit.save(traced_cpu, \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, write a `main.py` file with the following content and compress it along with the exported model with the name `submission.zip` to submit into the challenge platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from tifffile import imsave, imread\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "images_path = Path('/codeexecution/data/test_features')\n",
    "predictions_path = Path('/codeexecution/predictions')\n",
    "chip_ids = os.listdir(images_path)\n",
    "bands = ['B02', 'B03', 'B04', 'B08']\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, images):\n",
    "        super().__init__()\n",
    "        self.images = images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chip_id = self.images[idx]\n",
    "        img = [imread(images_path / chip_id / f'{band}.tif') for band in bands]\n",
    "        img = np.stack(img, axis=-1).astype(np.float32)\n",
    "        return torch.from_numpy(img), chip_id\n",
    "\n",
    "\n",
    "ds = MyDataset(chip_ids)\n",
    "\n",
    "dl = DataLoader(ds, batch_size=64, shuffle=False,\n",
    "                num_workers=4, pin_memory=True)\n",
    "\n",
    "model = torch.jit.load(\"model.pt\")\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "for batch in dl:\n",
    "    imgs, chips = batch\n",
    "    with torch.no_grad():\n",
    "        pred = model(imgs.cuda())\n",
    "    masks = torch.sigmoid(pred) > 0.5\n",
    "    masks = masks.cpu().numpy().astype(np.uint8)\n",
    "    for i, chip in enumerate(chips):\n",
    "        imsave(predictions_path / f'{chip}.tif', masks[i, ...])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Pytorch 1.8 is required at the moment of this writing ! This is the version used in the scoring platform and different versions may cause conflicts with `torchscript`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you like the library, we are planning to include more datasets and tasks in the future. If you find it useful please get in touch !!!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74dbfc52f168b3071122cf9c0781887d6121c12f9c1b29bca56ce221bccb2a07"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
